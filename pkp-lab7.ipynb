{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Labor 7\n",
        "\n",
        "\n",
        "A laboron az osztott és konstans memóriát is használó, rácsozott / csempézett (angolul tiled), kurzuson már ismertetett, képkonvolúció kernelt próbáljuk ki. Egy konstans méretű 5x5-ös konvolúciós maszkkal dolgozunk. A képek mérete  tetszőleges.\n",
        "\n",
        "\n",
        "\n",
        "Ahhoz, hogy a konvolúciós maszkot a konstans memóriában tároljuk,  ez át kell másolnunk az eszközre. Ha a maszk mutató neve `M `az eszközön, akkor  a kernel definiálásakor használhatjuk a const `float *  __restrict__ M` mutató dekorálást.\n",
        "\n",
        "\n",
        "```cpp\n",
        "__global__ void convolution(float *I, const float *__restrict__ M,\n",
        "                            float *P, int channels, int width,\n",
        "                            int height)\n",
        "\n",
        "```\n",
        "\n",
        "Ez a leírás tájékoztatja a fordítót arról, hogy a maszk tömb tartalma állandó, és csak az `M` mutatóváltozón keresztül érhető el. Ez lehetővé teszi a fordító számára, hogy az adatokat konstans (csak olvasható) memóriába helyezze, és lehetővé teszi az SM hardver számára, hogy futás közben agresszívebb módon gyorsítótárba helyezze (cachelje) a maszkadatokat.\n",
        "\n",
        "A  [`__restrict__`]( https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#restrict) dekorátor használata csak CC3.5 fölött érhető el, de használata egyszerűbb mint a [`__constant__`]( https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#constant) memóriaterület-specifikátor használata. Továbbá, míg a konstans memóriába másolható maximális adatmennyiség 64 Kb, a `__restrict__`-el megjelölt mutatók esetében nincs egy fix felső határ. \n",
        "\n",
        "\n",
        "## Pszeudokód\n",
        "\n",
        "\n",
        "```\n",
        "maskWidth := 5\n",
        "maskRadius := maskWidth/2 # this is integer division, so the result is 2 \n",
        "for i from 0 to height do\n",
        "  for j from 0 to width do \n",
        "    for k from 0 to channels\n",
        "      accum := 0\n",
        "      for y from -maskRadius to maskRadius do\n",
        "        for x from -maskRadius to maskRadius do \n",
        "          xOffset := j + x\n",
        "          yOffset := i + y\n",
        "          if xOffset >= 0 && xOffset < width &&\n",
        "            yOffset >= 0 && yOffset < height then\n",
        "              imagePixel := I[(yOffset * width + xOffset) * channels + k] \n",
        "              maskValue := K[(y+maskRadius)*maskWidth+x+maskRadius]\n",
        "              accum += imagePixel * maskValue\n",
        "          end \n",
        "        end\n",
        "      end\n",
        "        # pixels are in the range of 0 to 1\n",
        "      P[(i * width + j)*channels + k] = clamp(accum, 0, 1) \n",
        "    end\n",
        "  end\n",
        "end\n",
        "\n",
        "def clamp(x, lower, upper)\n",
        "  return min(max(x, lower), upper)\n",
        "end\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "# Feladat\n",
        "\n",
        "Implementáljuk a fentebbi programvázat. Főbb műveletek, részfeladatok:\n",
        "\n",
        "- memória lefoglalás az eszközön.\n",
        "- kép másolása az eszközre.\n",
        "- szálblokk és rács méreteinek, konfigurációjának a meghatározása. \n",
        "- CUDA kernel meghívása.\n",
        "- az eredmény másolása az eszközről a gazdagépre (host).\n",
        "- memória felszabadítása az eszközön\n",
        "- 2D \"csempézett\" konvolúciós kernel implementálása több színcsatornás képekre\n",
        "- osztott memóriát használva csökkentsük a globális memória hozzáférések számát (a képadatok osztott memóriába való betöltésekor figyelni kell a peremfeltételekre - a maszk részlegesen kilóg a képről).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ikVGiziWBV53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU teszt:"
      ],
      "metadata": {
        "id": "6L8pykxOK6s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "tcQWOk8UK9z1",
        "outputId": "f033e9b7-14b3-43c6-b95d-7623f7603c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d1680108c58e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conv.cu\n",
        "\n",
        "#include \"libgputk/gputk.h\"\n",
        "#include \"limits.h\"\n",
        "\n",
        "static char *base_dir;\n",
        "\n",
        "char *generateInput(int /*datasetNum*/, char *dirName,\n",
        "                    gpuTKGenerateParams_t params) {\n",
        "  char *input_file_name = gpuTKPath_join(dirName, \"input0.ppm\");\n",
        "  gpuTKDataset_generate(input_file_name, gpuTKExportKind_ppm, params);\n",
        "  return input_file_name;\n",
        "}\n",
        "\n",
        "char *generateMask(int /*datasetNum*/, char *dirName) {\n",
        "  // Mask generation parameters\n",
        "  gpuTKRaw_GenerateParams_t raw_params;\n",
        "  raw_params.rows   = 5;\n",
        "  raw_params.cols   = 5;\n",
        "  raw_params.minVal = 0;\n",
        "  raw_params.maxVal = 1.0f / 25.0f;\n",
        "  raw_params.type   = gpuTKType_float;\n",
        "\n",
        "  // Generation parameters are just the image generation parameters\n",
        "  gpuTKGenerateParams_t params;\n",
        "  params.raw = raw_params;\n",
        "\n",
        "  char *mask_file_name = gpuTKPath_join(dirName, \"input1.raw\");\n",
        "  gpuTKDataset_generate(mask_file_name, gpuTKExportKind_raw, params);\n",
        "  return mask_file_name;\n",
        "}\n",
        "\n",
        "float clamp(float x) {\n",
        "  return std::min(std::max(x, 0.0f), 1.0f);\n",
        "}\n",
        "\n",
        "void compute(gpuTKImage_t output, gpuTKImage_t input, float *mask, int mask_rows,\n",
        "             int mask_cols) {\n",
        "\n",
        "  const int num_channels = 3;\n",
        "\n",
        "  float *inputData  = gpuTKImage_getData(input);\n",
        "  float *outputData = gpuTKImage_getData(output);\n",
        "\n",
        "  int img_width  = gpuTKImage_getWidth(input);\n",
        "  int img_height = gpuTKImage_getHeight(input);\n",
        "\n",
        "  assert(img_width == gpuTKImage_getWidth(output));\n",
        "  assert(img_height == gpuTKImage_getHeight(output));\n",
        "  assert(mask_rows % 2 == 1);\n",
        "  assert(mask_cols % 2 == 1);\n",
        "\n",
        "  int mask_radius_y = mask_rows / 2;\n",
        "  int mask_radius_x = mask_cols / 2;\n",
        "\n",
        "  for (int out_y = 0; out_y < img_height; ++out_y) {\n",
        "    for (int out_x = 0; out_x < img_width; ++out_x) {\n",
        "      for (int c = 0; c < num_channels; ++c) { // channels\n",
        "        float acc = 0;\n",
        "        for (int off_y = -mask_radius_y; off_y <= mask_radius_y; ++off_y) {\n",
        "          for (int off_x = -mask_radius_x; off_x <= mask_radius_x;\n",
        "               ++off_x) {\n",
        "            int in_y   = out_y + off_y;\n",
        "            int in_x   = out_x + off_x;\n",
        "            int mask_y = mask_radius_y + off_y;\n",
        "            int mask_x = mask_radius_x + off_x;\n",
        "            if (in_y < img_height && in_y >= 0 && in_x < img_width &&\n",
        "                in_x >= 0) {\n",
        "              acc +=\n",
        "                  inputData[(in_y * img_width + in_x) * num_channels + c] *\n",
        "                  mask[mask_y * mask_cols + mask_x];\n",
        "            } else {\n",
        "              acc += 0.0f;\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "        // fprintf(stderr, \"%f %f\\n\", clamp(acc));\n",
        "        outputData[(out_y * img_width + out_x) * num_channels + c] =\n",
        "            clamp(acc);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "void generate(int datasetNum, int height, int width, int minVal,\n",
        "              int maxVal) {\n",
        "  char *dir_name = gpuTKPath_join(base_dir, datasetNum);\n",
        "\n",
        "  // Image generation parameters\n",
        "  gpuTKPPM_GenerateParams_t ppm_params;\n",
        "  ppm_params.height   = height;\n",
        "  ppm_params.width    = width;\n",
        "  ppm_params.channels = 3;\n",
        "  ppm_params.minVal   = minVal;\n",
        "  ppm_params.maxVal   = maxVal;\n",
        "\n",
        "  // Generation parameters are just the image generation parameters\n",
        "  gpuTKGenerateParams_t params;\n",
        "  params.ppm = ppm_params;\n",
        "\n",
        "  char *input_image_file_name =\n",
        "      generateInput(datasetNum, dir_name, params);\n",
        "  char *input_mask_file_name = generateMask(datasetNum, dir_name);\n",
        "\n",
        "  // Import mask and image\n",
        "  gpuTKImage_t inputImage = gpuTKImport(input_image_file_name);\n",
        "  int mask_rows, mask_cols;\n",
        "  float *mask_data =\n",
        "      (float *)gpuTKImport(input_mask_file_name, &mask_rows, &mask_cols);\n",
        "\n",
        "  // Create output image\n",
        "  gpuTKImage_t outputImage = gpuTKImage_new(width, height, 3);\n",
        "  compute(outputImage, inputImage, mask_data, mask_rows, mask_cols);\n",
        "\n",
        "  // Exporto output image\n",
        "  char *output_file_name = gpuTKPath_join(dir_name, \"output.ppm\");\n",
        "  gpuTKExport(output_file_name, outputImage);\n",
        "\n",
        "  free(input_image_file_name);\n",
        "  free(input_mask_file_name);\n",
        "  free(output_file_name);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  base_dir = gpuTKPath_join(gpuTKDirectory_current(), \"Convolution\", \"Dataset\");\n",
        "  generate(0, 64, 64, 0, 1);\n",
        "  generate(1, 128, 64, 0, 1);\n",
        "  generate(2, 64, 128, 0, 1);\n",
        "  generate(3, 64, 5, 0, 1);\n",
        "  generate(4, 64, 3, 0, 1);\n",
        "  generate(5, 228, 128, 0, 1);\n",
        "  generate(6, 28, 12, 0, 1);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJvSohmtRvmb",
        "outputId": "944229d3-4912-4724-b3c2-e3590dfdfcfd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing conv.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run\n",
        "!chmod +x cuda_11.4.0_470.42.01_linux.run\n",
        "!./cuda_11.4.0_470.42.01_linux.run --silent --toolkit --override\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4SDD9g6xHDw",
        "outputId": "43c27c77-2fe7-41ad-df20-104f168de382"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-18 12:15:36--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2023-05-18 12:15:36--  https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3773273383 (3.5G) [application/octet-stream]\n",
            "Saving to: ‘cuda_11.4.0_470.42.01_linux.run.1’\n",
            "\n",
            "cuda_11.4.0_470.42. 100%[===================>]   3.51G   236MB/s    in 15s     \n",
            "\n",
            "2023-05-18 12:15:52 (235 MB/s) - ‘cuda_11.4.0_470.42.01_linux.run.1’ saved [3773273383/3773273383]\n",
            "\n",
            "FINISHED --2023-05-18 12:15:52--\n",
            "Total wall clock time: 15s\n",
            "Downloaded: 1 files, 3.5G in 15s (235 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc conv.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3hioSonzEEC",
        "outputId": "8c9e06d6-12cc-4865-e90b-0bc8bc83b2bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[Kconv.cu:2:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Klibgputk/gputk.h: No such file or directory\n",
            "    2 | #include \u001b[01;31m\u001b[K\"libgputk/gputk.h\"\u001b[m\u001b[K\n",
            "      |          \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n"
          ]
        }
      ]
    }
  ]
}